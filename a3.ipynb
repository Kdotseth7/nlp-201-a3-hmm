{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "475205c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a7791fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('House', 'NNP'), ('joined', 'VBD'), ('the', 'DT'), ('Senate', 'NNP'), ('in', 'IN'), ('making', 'VBG'), ('federal', 'JJ'), ('reparations', 'NNS'), ('for', 'IN'), ('Japanese-Americans', 'NNPS')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:22: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:22: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/var/folders/hk/l7897jp170bb9tbb20n80tz00000gn/T/ipykernel_96255/1142039552.py:22: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if sent is not \"\":\n"
     ]
    }
   ],
   "source": [
    "# Functions from starter_code.py\n",
    "def evaluate(test_sentences, tagged_test_sentences, output_dict=False):\n",
    "    gold = [str(tag) for sentence in test_sentences for token, tag in sentence]\n",
    "    pred = [\n",
    "        str(tag)\n",
    "        for sentence in tagged_test_sentences\n",
    "        for token, tag in sentence\n",
    "    ]\n",
    "    return metrics.classification_report(gold, pred, output_dict=output_dict)\n",
    "\n",
    "def get_token_tag_tuples(sent):\n",
    "    return [nltk.tag.str2tuple(t) for t in sent.split()]\n",
    "\n",
    "def get_tagged_sentences(text):\n",
    "    sentences = []\n",
    "\n",
    "    blocks = text.split(\"======================================\")\n",
    "    for block in blocks:\n",
    "        sents = block.split(\"\\n\\n\")\n",
    "        for sent in sents:\n",
    "            sent = sent.replace(\"\\n\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            if sent is not \"\":\n",
    "                sentences.append(sent)\n",
    "    return sentences\n",
    "\n",
    "def load_treebank_splits(datadir):\n",
    "\n",
    "    train = []\n",
    "    dev = []\n",
    "    test = []\n",
    "\n",
    "    print(\"Loading treebank data...\")\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(datadir):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".pos\"):\n",
    "                filepath = subdir + os.sep + filename\n",
    "                with open(filepath, \"r\") as fh:\n",
    "                    text = fh.read()\n",
    "                    if int(subdir.split(os.sep)[-1]) in range(0, 19):\n",
    "                        train += get_tagged_sentences(text)\n",
    "\n",
    "                    if int(subdir.split(os.sep)[-1]) in range(19, 22):\n",
    "                        dev += get_tagged_sentences(text)\n",
    "                    \n",
    "                    if int(subdir.split(os.sep)[-1]) in range(22, 25):\n",
    "                        test += get_tagged_sentences(text)\n",
    "\n",
    "    print(\"Train set size: \", len(train))\n",
    "    print(\"Dev set size: \", len(dev))\n",
    "    print(\"Test set size: \", len(test))\n",
    "\n",
    "    return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6f89e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Helper Function\n",
    "def print_result(result, name=\"\"):\n",
    "    print(\"==================\")\n",
    "    print(name)\n",
    "    print(\"==================\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2d7301e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcess():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Special Tokens\n",
    "        self.SOS = '<START>'\n",
    "        self.EOS = '<STOP>'\n",
    "        self.UNK = '<UNK>'\n",
    "\n",
    "    def preprocess_dataset(self, \n",
    "                           dataset):\n",
    "        preprocessed_ds = [([(self.SOS, self.SOS)] + get_token_tag_tuples(sentence) + [(self.EOS, self.EOS)]) for sentence in dataset]\n",
    "        return preprocessed_ds\n",
    "\n",
    "    def remove_start_stop(self, \n",
    "                          dataset):\n",
    "        return [sentence[1:-1] for sentence in dataset]\n",
    "\n",
    "    def get_words_tags(self, \n",
    "                       dataset, \n",
    "                       words):\n",
    "        word_tag_list = []\n",
    "        for sentence in dataset:\n",
    "            if words == True:\n",
    "                word_tag_list.append([word for word, tag in sentence])\n",
    "            else:\n",
    "                word_tag_list.append([tag for word, tag in sentence])\n",
    "        return word_tag_list\n",
    "    \n",
    "    def preprocess_flatten_corpus(self, \n",
    "                                  dataset, \n",
    "                                  preprocess):\n",
    "        return [token for sent in dataset for token in preprocess(sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "887e975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading treebank data...\n",
      "Train set size:  51681\n",
      "Dev set size:  7863\n",
      "Test set size:  9046\n"
     ]
    }
   ],
   "source": [
    "# Set path for datadir\n",
    "datadir = os.path.join(\"data\", \"penn-treebank3-wsj\", \"wsj\")\n",
    "train, dev, test = load_treebank_splits(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4fc29549",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = PreProcess()\n",
    "\n",
    "# extract the gold from dev/test set\n",
    "gold_dev = pp.preprocess_dataset(dev)\n",
    "gold_test = pp.preprocess_dataset(test)\n",
    "\n",
    "# the train set contained labels\n",
    "train_corpus = train\n",
    "\n",
    "# the dev/test set without labels\n",
    "dev_corpus = pp.get_words_tags(gold_dev, True)\n",
    "test_corpus = pp.get_words_tags(gold_test, True)\n",
    "\n",
    "# remove special tokens for golds\n",
    "gold_dev = pp.remove_start_stop(gold_dev)\n",
    "gold_test = pp.remove_start_stop(gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "30508b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineTagger:\n",
    "    def __init__(self):\n",
    "        self.corpus = []  # training corpus\n",
    "\n",
    "        self.most_frequent_table = (\n",
    "            {}\n",
    "        )  # key:val = word:most_freq_tag_of_such_word\n",
    "        self.most_common_tag = (\n",
    "            \"\"  # the most frequent tag no matter what word it is\n",
    "        )\n",
    "\n",
    "    def train(self, corpus):\n",
    "        self.corpus = [preprocess.preprocess_labeled_text(sent) for sent in corpus]\n",
    "\n",
    "        word_tag_frequent_table = {}\n",
    "        tag_counts = {}\n",
    "\n",
    "        # calculate all the word:tag count and individual tag count\n",
    "        for sent in self.corpus:\n",
    "            for token in sent:\n",
    "                word, tag = token\n",
    "                tag_frequency = word_tag_frequent_table.get(word, {})\n",
    "                tag_frequency[tag] = tag_frequency.get(tag, 0) + 1\n",
    "                word_tag_frequent_table[word] = tag_frequency\n",
    "                tag_counts[tag] = tag_counts.get(tag, 0) + 1\n",
    "\n",
    "        # calculate the most frequent tag for word\n",
    "        for word, tag_freq in word_tag_frequent_table.items():\n",
    "            self.most_frequent_table[word] = max(\n",
    "                tag_freq.items(), key=lambda x: x[1]\n",
    "            )[0]\n",
    "        # calculate the most frequent tag among all tags\n",
    "        self.most_common_tag = max(tag_counts.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "    def predict(self, corpus):\n",
    "        tags = []\n",
    "        for sent in corpus:\n",
    "            tag_seq = []\n",
    "            for word in sent:\n",
    "                # if word in the dictionary, get the most frequent tag\n",
    "                # if not just give most common tag\n",
    "                tag = self.most_frequent_table.get(word, self.most_common_tag)\n",
    "                tag_seq.append((word, tag))\n",
    "            tags.append(tag_seq)\n",
    "        return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2bd91427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMMTagger:\n",
    "    def __init__(self):\n",
    "        # preprocessed and labeled corpus for the POS task\n",
    "        self.corpus = []\n",
    "        # frequency of word tokens\n",
    "        self.vocab = {}\n",
    "        # all type of tags\n",
    "        self.tag_list = []\n",
    "        # table for the transition prob of all combination of tag->tag in the corpus\n",
    "        self.transition_table = []\n",
    "        # table for the emission prob of all combination of word:tag in the corpus\n",
    "        self.emission_table = []\n",
    "        # the emission probability for <UNK>:tag => actually it is just a prob for every single tag\n",
    "        self.unknown_emission_prob = {}\n",
    "\n",
    "    def train(self, corpus, alpha=1):\n",
    "        self.corpus = [preprocess.preprocess_labeled_text(sent) for sent in corpus]\n",
    "        self.vocab = self.get_vocab(self.corpus)\n",
    "        (\n",
    "            self.transition_table,\n",
    "            self.emission_table,\n",
    "            self.unknown_emission_prob,\n",
    "            self.tag_list,\n",
    "        ) = self.build_tables(alpha)\n",
    "\n",
    "        self.word2idx = {\n",
    "            word: idx for idx, word in enumerate(self.vocab.keys())\n",
    "        }\n",
    "        self.tag2idx = {tag: idx for idx, tag in enumerate(self.tag_list)}\n",
    "        self.idx2word = {\n",
    "            idx: word for idx, word in enumerate(self.vocab.keys())\n",
    "        }\n",
    "        self.idx2tag = {idx: tag for idx, tag in enumerate(self.tag_list)}\n",
    "\n",
    "    def build_tables(self, alpha=1):\n",
    "        # key is prev tag and current tag, value is count\n",
    "        transitions = self.get_transitions(self.corpus)\n",
    "        # key is tag, token, value is count\n",
    "        emissions = self.get_emissions(self.corpus)\n",
    "\n",
    "        # store frequency of each tag\n",
    "        tag_dict = self.get_tag_freq(self.corpus)\n",
    "        tag_list = tag_dict.keys()\n",
    "\n",
    "        transition_table = self.create_transition_table(\n",
    "            transitions, tag_dict, tag_list, alpha\n",
    "        )\n",
    "        emission_table, unknown_emission_prob = self.create_emission_table(\n",
    "            emissions, tag_dict, tag_list, self.vocab, alpha\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            transition_table,\n",
    "            emission_table,\n",
    "            unknown_emission_prob,\n",
    "            tag_list,\n",
    "        )\n",
    "\n",
    "    def get_vocab(self, sents):\n",
    "        vocab = {}\n",
    "        for sent in sents:\n",
    "            for token in sent:\n",
    "                word = token[0]\n",
    "                vocab[word] = vocab.get(word, 0) + 1\n",
    "        return vocab\n",
    "\n",
    "    def get_transitions(self, sents):\n",
    "        transitions = {}\n",
    "        for sent in sents:\n",
    "            for i in range(1, len(sent)):\n",
    "                bigram_tags = (sent[i - 1][1], sent[i][1])\n",
    "                transitions[bigram_tags] = transitions.get(bigram_tags, 0) + 1\n",
    "        return transitions\n",
    "\n",
    "    def get_emissions(self, sents):\n",
    "        emissions = {}\n",
    "        for sent in sents:\n",
    "            for token_tag_pair in sent:\n",
    "                emissions[token_tag_pair] = (\n",
    "                    emissions.get(token_tag_pair, 0) + 1\n",
    "                )\n",
    "        return emissions\n",
    "\n",
    "    def get_tag_freq(self, sents):\n",
    "        tag_dict = {}\n",
    "        for sent in sents:\n",
    "            for _, tag in sent:\n",
    "                tag_dict[tag] = tag_dict.get(tag, 0) + 1\n",
    "        return tag_dict\n",
    "\n",
    "    def create_transition_table(self, transitions, tag_dict, tags, alpha=1):\n",
    "        transition_table = []  # 2-dim list\n",
    "        for prev_tag in tags:\n",
    "            prob_list = []\n",
    "            for current_tag in tags:\n",
    "                prev_count = tag_dict.get(prev_tag, 0)\n",
    "                bigram_count = transitions.get((prev_tag, current_tag), 0)\n",
    "                prob = (bigram_count + alpha) / (\n",
    "                    prev_count + (alpha * len(tags))\n",
    "                )\n",
    "                prob_list.append(np.log(prob))\n",
    "            transition_table.append(prob_list)\n",
    "        return transition_table\n",
    "\n",
    "    def create_emission_table(self, emissions, tag_dict, tags, vocab, alpha):\n",
    "        emission_table = []  # 2-dim list\n",
    "        unknown_emission_prob = {}\n",
    "        total_tag_counts = sum(tag_dict.values())\n",
    "        for tag in tags:\n",
    "            prob_list = []\n",
    "            tag_count = tag_dict.get(tag, 0)\n",
    "            for word in vocab.keys():\n",
    "                word_tag_count = emissions.get((word, tag), 0)\n",
    "                prob = (word_tag_count + alpha) / (\n",
    "                    tag_count + (alpha * len(tags))\n",
    "                )\n",
    "                prob_list.append(np.log(prob))\n",
    "            emission_table.append(prob_list)\n",
    "            unknown_emission_prob[tag] = (tag_count + alpha) / (\n",
    "                total_tag_counts + (alpha * len(tags))\n",
    "            )\n",
    "        return emission_table, unknown_emission_prob\n",
    "\n",
    "    def viterbi_decode(self, sent):\n",
    "        tags = []\n",
    "        viterbi_matrix = []\n",
    "\n",
    "        # Initial step\n",
    "        initial = []  # empty array for start token\n",
    "        viterbi_matrix.append(initial)\n",
    "        first_token = sent[1]\n",
    "        first_token_scores = []\n",
    "        for i, tag in enumerate(self.tag_list):\n",
    "            transition_prob = self.transition_table[self.tag2idx[preprocess.SOS]][\n",
    "                i\n",
    "            ]\n",
    "            emission_prob = self.unknown_emission_prob[tag]\n",
    "            if first_token in self.word2idx.keys():\n",
    "                emission_prob = self.emission_table[i][\n",
    "                    self.word2idx[first_token]\n",
    "                ]\n",
    "            # calculate all the tag start from the start token\n",
    "            first_token_scores.append(\n",
    "                (self.tag2idx[preprocess.SOS], transition_prob + emission_prob)\n",
    "            )\n",
    "        viterbi_matrix.append(first_token_scores)\n",
    "\n",
    "        # recursive step\n",
    "        for t, token in enumerate(sent):\n",
    "            if t <= 1:\n",
    "                continue\n",
    "            max_scores = []\n",
    "            for i, tag in enumerate(self.tag_list):\n",
    "                max_score = float(\"-inf\")\n",
    "                candidate = None\n",
    "                emission_prob = self.unknown_emission_prob[tag]\n",
    "                if token in self.word2idx.keys():\n",
    "                    emission_prob = self.emission_table[i][\n",
    "                        self.word2idx[token]\n",
    "                    ]\n",
    "                # go through every previous score that already be calculated in the viterbi matrix\n",
    "                for j, score in enumerate(viterbi_matrix[t - 1]):\n",
    "                    _, prev_max_log_prob = score\n",
    "                    transition_prob = self.transition_table[j][i]\n",
    "                    new_score = (\n",
    "                        emission_prob + transition_prob + prev_max_log_prob\n",
    "                    )\n",
    "                    if new_score > max_score:\n",
    "                        max_score = new_score\n",
    "                        candidate = j\n",
    "                max_scores.append((candidate, max_score))\n",
    "            viterbi_matrix.append(max_scores)\n",
    "\n",
    "        # start with the stop tag\n",
    "        max_tag = self.tag2idx[preprocess.EOS]\n",
    "        tags.append((preprocess.EOS, self.idx2tag[max_tag]))\n",
    "\n",
    "        # find best path in viterbi matrix\n",
    "        for i in reversed(range(1, len(viterbi_matrix))):\n",
    "            max_tag = viterbi_matrix[i][max_tag][0]\n",
    "            tags.append((sent[i - 1], self.idx2tag[max_tag]))\n",
    "\n",
    "        # since it is found backward, we need to reverse it\n",
    "        tags.reverse()\n",
    "        return tags\n",
    "\n",
    "    def predict(self, corpus):\n",
    "        all_tags = []\n",
    "        for sent in tqdm(corpus):\n",
    "            prediction_tags = self.viterbi_decode(sent)\n",
    "            all_tags.append(prediction_tags)\n",
    "        return all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0f645609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagraseth/Documents/pvenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kushagraseth/Documents/pvenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kushagraseth/Documents/pvenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Baseline_Dev\n",
      "==================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       1.00      1.00      1.00        31\n",
      "           $       1.00      1.00      1.00      1248\n",
      "          ''       1.00      0.98      0.99      1168\n",
      "           (       1.00      1.00      1.00       244\n",
      "           )       1.00      1.00      1.00       244\n",
      "           ,       1.00      1.00      1.00      7931\n",
      "           .       1.00      1.00      1.00      6125\n",
      "           :       1.00      1.00      1.00       775\n",
      "          CC       0.99      0.99      0.99      3777\n",
      "          CD       0.99      0.90      0.94      5766\n",
      "          DT       0.99      0.98      0.99     12639\n",
      "          EX       0.86      1.00      0.92       133\n",
      "          FW       0.53      0.40      0.45        25\n",
      "          IN       0.95      0.98      0.96     15497\n",
      "       IN|RB       0.00      0.00      0.00         1\n",
      "          JJ       0.88      0.84      0.86      9014\n",
      "         JJR       0.72      0.92      0.81       506\n",
      "         JJS       0.85      0.96      0.90       303\n",
      "          LS       0.00      0.00      0.00         2\n",
      "          MD       0.99      1.00      1.00      1455\n",
      "          NN       0.78      0.94      0.85     20734\n",
      "         NNP       0.96      0.85      0.90     14989\n",
      "        NNPS       0.71      0.56      0.62       470\n",
      "         NNS       0.97      0.93      0.95      9089\n",
      "      NNS|NN       0.00      0.00      0.00         1\n",
      "    NNS|NNPS       0.00      0.00      0.00         1\n",
      "       NN|JJ       0.00      0.00      0.00         2\n",
      "      NN|NNS       0.00      0.00      0.00         1\n",
      "         PDT       0.00      0.00      0.00        72\n",
      "         POS       0.88      1.00      0.94      1412\n",
      "         PRP       0.99      0.99      0.99      2673\n",
      "        PRP$       0.99      1.00      1.00      1317\n",
      "          RB       0.91      0.85      0.88      4789\n",
      "         RBR       0.49      0.27      0.35       240\n",
      "     RBR|JJR       0.00      0.00      0.00         1\n",
      "         RBS       0.00      0.00      0.00        52\n",
      "     RBS|JJS       0.00      0.00      0.00         1\n",
      "       RB|RP       0.00      0.00      0.00         2\n",
      "          RP       0.31      0.14      0.20       203\n",
      "         SYM       1.00      1.00      1.00         4\n",
      "          TO       1.00      1.00      1.00      3441\n",
      "          UH       0.80      0.25      0.38        16\n",
      "          VB       0.78      0.70      0.74      3948\n",
      "         VBD       0.87      0.84      0.86      5198\n",
      "     VBD|VBN       0.00      0.00      0.00         1\n",
      "         VBG       0.90      0.85      0.87      2204\n",
      "      VBG|JJ       0.00      0.00      0.00         1\n",
      "      VBG|NN       0.00      0.00      0.00         4\n",
      "         VBN       0.71      0.74      0.72      3143\n",
      "      VBN|JJ       0.00      0.00      0.00         1\n",
      "     VBN|VBD       0.00      0.00      0.00         1\n",
      "         VBP       0.73      0.71      0.72      1678\n",
      "         VBZ       0.96      0.88      0.92      3118\n",
      "         WDT       1.00      0.51      0.68       606\n",
      "          WP       0.99      1.00      1.00       354\n",
      "         WP$       1.00      1.00      1.00        19\n",
      "         WRB       1.00      1.00      1.00       310\n",
      "          ``       1.00      1.00      1.00      1177\n",
      "\n",
      "    accuracy                           0.91    148157\n",
      "   macro avg       0.65      0.62      0.63    148157\n",
      "weighted avg       0.92      0.91      0.91    148157\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagraseth/Documents/pvenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kushagraseth/Documents/pvenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kushagraseth/Documents/pvenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kushagraseth/Documents/pvenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kushagraseth/Documents/pvenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kushagraseth/Documents/pvenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Baseline_Test\n",
      "==================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       1.00      1.00      1.00        22\n",
      "           $       1.00      1.00      1.00      1138\n",
      "          ''       1.00      0.99      1.00      1423\n",
      "           (       1.00      1.00      1.00       249\n",
      "           )       1.00      1.00      1.00       252\n",
      "           ,       1.00      1.00      1.00      9056\n",
      "           .       1.00      1.00      1.00      7035\n",
      "           :       1.00      1.00      1.00       983\n",
      "          CC       1.00      1.00      1.00      4289\n",
      "          CD       0.99      0.90      0.94      6023\n",
      "          DT       0.99      0.99      0.99     14946\n",
      "          EX       0.89      1.00      0.94       174\n",
      "          FW       0.35      0.21      0.26        38\n",
      "          IN       0.94      0.98      0.96     18147\n",
      "          JJ       0.88      0.86      0.87     10704\n",
      "         JJR       0.66      0.95      0.78       581\n",
      "     JJR|RBR       0.00      0.00      0.00         4\n",
      "         JJS       0.79      0.95      0.86       374\n",
      "       JJ|IN       0.00      0.00      0.00         1\n",
      "          LS       0.00      0.00      0.00        15\n",
      "          MD       0.99      1.00      0.99      1674\n",
      "          NN       0.80      0.94      0.87     23468\n",
      "         NNP       0.97      0.86      0.91     17236\n",
      "        NNPS       0.27      0.46      0.34       239\n",
      "         NNS       0.97      0.94      0.96     10697\n",
      "     NNS|VBZ       0.00      0.00      0.00         0\n",
      "         PDT       0.00      0.00      0.00        66\n",
      "         POS       0.87      1.00      0.93      1638\n",
      "         PRP       1.00      0.99      1.00      2930\n",
      "        PRP$       0.99      1.00      0.99      1433\n",
      "          RB       0.90      0.86      0.88      5853\n",
      "         RBR       0.83      0.24      0.37       382\n",
      "     RBR|JJR       0.00      0.00      0.00         2\n",
      "         RBS       0.40      0.02      0.04        87\n",
      "       RB|JJ       0.00      0.00      0.00         2\n",
      "          RP       0.34      0.12      0.17       356\n",
      "         SYM       0.82      0.82      0.82        11\n",
      "          TO       1.00      1.00      1.00      3899\n",
      "          UH       1.00      0.50      0.67        20\n",
      "          VB       0.79      0.69      0.74      4766\n",
      "         VBD       0.87      0.84      0.85      5869\n",
      "         VBG       0.90      0.85      0.87      2592\n",
      "      VBG|NN       0.00      0.00      0.00         1\n",
      "         VBN       0.73      0.72      0.72      3580\n",
      "      VBN|JJ       0.00      0.00      0.00         2\n",
      "         VBP       0.75      0.71      0.73      2209\n",
      "         VBZ       0.95      0.87      0.91      3608\n",
      "         WDT       1.00      0.54      0.70       773\n",
      "          WP       0.99      1.00      0.99       397\n",
      "         WP$       1.00      1.00      1.00        47\n",
      "         WRB       1.00      0.99      1.00       425\n",
      "          ``       1.00      1.00      1.00      1422\n",
      "\n",
      "    accuracy                           0.92    171138\n",
      "   macro avg       0.72      0.69      0.69    171138\n",
      "weighted avg       0.92      0.92      0.92    171138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                      | 233/7863 [00:03<01:48, 70.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [154], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluate(gold_dev, prediction_dev, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     87\u001b[0m experiment_baseline()\n\u001b[0;32m---> 88\u001b[0m experiment_hmm()\n",
      "Cell \u001b[0;32mIn [154], line 48\u001b[0m, in \u001b[0;36mexperiment_hmm\u001b[0;34m(alpha)\u001b[0m\n\u001b[1;32m     45\u001b[0m hmm_tagger\u001b[38;5;241m.\u001b[39mtrain(train_corpus, alpha)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# dev\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m prediction_dev \u001b[38;5;241m=\u001b[39m \u001b[43mhmm_tagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev_corpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m prediction_dev \u001b[38;5;241m=\u001b[39m preprocess\u001b[38;5;241m.\u001b[39mpreprocess_corpus(\n\u001b[1;32m     50\u001b[0m     prediction_dev, preprocess\u001b[38;5;241m.\u001b[39mpreprocess_remove_start_stop_tokens\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m print_result(\n\u001b[1;32m     53\u001b[0m     evaluate(gold_dev, prediction_dev), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHMM_Dev with alpha=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m )\n",
      "Cell \u001b[0;32mIn [152], line 190\u001b[0m, in \u001b[0;36mHMMTagger.predict\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    188\u001b[0m all_tags \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m tqdm(corpus):\n\u001b[0;32m--> 190\u001b[0m     prediction_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviterbi_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     all_tags\u001b[38;5;241m.\u001b[39mappend(prediction_tags)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_tags\n",
      "Cell \u001b[0;32mIn [152], line 168\u001b[0m, in \u001b[0;36mHMMTagger.viterbi_decode\u001b[0;34m(self, sent)\u001b[0m\n\u001b[1;32m    164\u001b[0m transition_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransition_table[j][i]\n\u001b[1;32m    165\u001b[0m new_score \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    166\u001b[0m     emission_prob \u001b[38;5;241m+\u001b[39m transition_prob \u001b[38;5;241m+\u001b[39m prev_max_log_prob\n\u001b[1;32m    167\u001b[0m )\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_score \u001b[38;5;241m>\u001b[39m max_score:\n\u001b[1;32m    169\u001b[0m     max_score \u001b[38;5;241m=\u001b[39m new_score\n\u001b[1;32m    170\u001b[0m     candidate \u001b[38;5;241m=\u001b[39m j\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# using small amount of samples for training and testing\n",
    "def experiment_debug(alpha=1):\n",
    "    train_samples = [\n",
    "        \"The/DT House/NNP joined/VBD  the/DT Senate/NNP in/IN making/VBG  federal/JJ reparations/NNS for/IN Japanese-Americans/NNPS\"\n",
    "    ]\n",
    "    test_samples = [\n",
    "        \"alsjfla the askdmc and djdsaas in making\",\n",
    "        \"vsacs the House and djdsaas in giuhun\",\n",
    "        \"The House joined  the Senate in making  federal reparations for Japanese-Americans\",\n",
    "    ]\n",
    "    tagger = HMMTagger()\n",
    "    tagger.train(train_samples, alpha)\n",
    "    hmm_y = tagger.predict(test_samples)\n",
    "\n",
    "    b_tagger = BaselineTagger()\n",
    "    b_tagger.train(train_corpus)\n",
    "    b_y = b_tagger.predict(test_samples)\n",
    "\n",
    "    hmm_y = preprocess.preprocess_corpus(hmm_y, preprocess.preprocess_remove_start_stop_tokens)\n",
    "    b_y = preprocess.preprocess_corpus(b_y, preprocess.preprocess_remove_start_stop_tokens)\n",
    "    print_result(evaluate(hmm_y, b_y), \"debug\")\n",
    "\n",
    "\n",
    "def experiment_baseline():\n",
    "    baseline_tagger = BaselineTagger()\n",
    "    baseline_tagger.train(train_corpus)\n",
    "\n",
    "    # dev\n",
    "    prediction_dev = baseline_tagger.predict(dev_corpus)\n",
    "    prediction_dev = preprocess.preprocess_corpus(\n",
    "        prediction_dev, preprocess.preprocess_remove_start_stop_tokens\n",
    "    )\n",
    "    print_result(evaluate(gold_dev, prediction_dev), \"Baseline_Dev\")\n",
    "\n",
    "    # test\n",
    "    prediction_test = baseline_tagger.predict(test_corpus)\n",
    "    prediction_test = preprocess.preprocess_corpus(\n",
    "        prediction_test, preprocess.preprocess_remove_start_stop_tokens\n",
    "    )\n",
    "    print_result(evaluate(gold_test, prediction_test), \"Baseline_Test\")\n",
    "\n",
    "\n",
    "def experiment_hmm(alpha=1):\n",
    "    hmm_tagger = HMMTagger()\n",
    "    hmm_tagger.train(train_corpus, alpha)\n",
    "\n",
    "    # dev\n",
    "    prediction_dev = hmm_tagger.predict(dev_corpus)\n",
    "    prediction_dev = preprocess.preprocess_corpus(\n",
    "        prediction_dev, preprocess.preprocess_remove_start_stop_tokens\n",
    "    )\n",
    "    print_result(\n",
    "        evaluate(gold_dev, prediction_dev), f\"HMM_Dev with alpha={alpha}\"\n",
    "    )\n",
    "\n",
    "    # test\n",
    "    prediction_test = hmm_tagger.predict(test_corpus)\n",
    "    prediction_test = preprocess.preprocess_corpus(\n",
    "        prediction_test, preprocess.preprocess_remove_start_stop_tokens\n",
    "    )\n",
    "    print_result(\n",
    "        evaluate(gold_test, prediction_test), f\"HMM_Test with alpha={alpha}\"\n",
    "    )\n",
    "\n",
    "    print_result(\n",
    "        ConfusionMatrix(\n",
    "            preprocess.preprocess_flatten_corpus(gold_test, preprocess.preprocess_extract_tags),\n",
    "            preprocess.preprocess_flatten_corpus(\n",
    "                prediction_test, preprocess.preprocess_extract_tags\n",
    "            ),\n",
    "        ),\n",
    "        f\"Confusion Matrix with alpha={alpha}\",\n",
    "    )\n",
    "\n",
    "\n",
    "def experiment_hmm_alpha(alpha=1):\n",
    "    hmm_tagger = HMMTagger()\n",
    "    hmm_tagger.train(train_corpus, alpha)\n",
    "\n",
    "    # dev\n",
    "    prediction_dev = hmm_tagger.predict(dev_corpus)\n",
    "    prediction_dev = preprocess.preprocess_corpus(\n",
    "        prediction_dev, preprocess.preprocess_remove_start_stop_tokens\n",
    "    )\n",
    "    return evaluate(gold_dev, prediction_dev, output_dict=True)\n",
    "\n",
    "experiment_baseline()\n",
    "experiment_hmm()\n",
    "# experiment_hmm(alpha=pow(10, -5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19128b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For evaluation against the default NLTK POS tagger\n",
    "\n",
    "# test_sentences = [get_token_tag_tuples(sent) for sent in test]\n",
    "# tagged_test_sentences = [nltk.pos_tag([token for token, tag in sentence]) for sentence in test_sentences]\n",
    "# evaluate(test_sentences, tagged_test_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
